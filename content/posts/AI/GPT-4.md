---
title: GPT-4
date: 2023-04-01T22:52:00+08:00
description: GPT-4模型
menu:
  sidebar:
    name: GPT-4
    identifier: AI-《GPT-4》
    parent: AI
    weight: 20230401
hero: /images/AI.jpeg
---

## 导言

`GPT-4`是目前[`OpenAI`](https://openai.com/)最新发布的多模态大模型，支持文本、图像作为输入，以纯文本的形式(也包括以代码的形式)作为输出。模型的能力非常强悍，在部分场景下，已经可以达到甚至超过现实世界人的水平。官方中有个例子是：以排名TOP 10%的结果通过律师资格认证考试（`GTP-3.5`模型还无法通过）。

其实，`GPT-4`在2022年8月份就已经完成了训练，之后经历了近半年的测试调整后（涵盖安全、合规等方面），才在2023年3月份发布。

## 训练

`OpenAI`基于微软云搭建了超级计算集群用于模型训练，`GPT-3.5`是第一个在上面完成训练的模型。在训练`GPT-3.5`的过程中，他们发现并修复了一些问题。

和以往的GPT模型一样，它也是用预测文章中下一个词的方式去训练的，也就是`Language Modeling Loss`。

### 数据来源

训练数据有包括公开的数据，比如网络数据，也有购买的数据。有数学问题中的正确解和错误解，有弱推理也有强推理，有保持一致的也有互相矛盾的，也有多种意识形态。

因为数据集中既有正确的信息，也有异常的信息，所以预训练后的base模型回答结果和人们所预期的还有很大的差距，所以他们采用了`RLHF`来做align微调。

`RLHF`是用来控制模型更能知道用户问的是什么，用户更希望要的是什么。

## 可预测的扩展性
一般情况下，大模型的训练代价非常大，非常耗费时间。我们需要先在小模型或者较小的数据集上去做消融实验，看看哪个想法work了，然后再去大的模型上做实验。

但是对于语言模型，由于模型扩展得太大了，所以往往会出现即使在小模型中测试通过的想法，换到大模型中也无法work。而且，在大模型下的涌现能力，也是无法在小模型中观测到的。

**但是，`OpenAI`表示，他们可以准确的预测`GPT-4`的训练结果。在小模型训练出来结果后，就可以预测出如果把计算成本扩大，这个模型最后的训练性能是怎样的。**

## 能力

在目前的测试结果来看，`GPT-4`对文字类的测试成果优秀，在编码及数学计算上，表现一般。

`GPT-4`具备代码生成能力，有人用餐巾纸手画了一个网站草图作为输入，它就能生成相关代码，并可正常运行。

支持多种语言，包括英文、中文等26种。

## 视觉输入

`GPT-4`模型支持用户以图片、文字或两者相混的方式作为输入。

官方有个例子，`GPT-4`可以读取用户提供的图片（用VGA插头插入手机充电口），为用户解释这张图片的搞笑点。

## 可操纵性

在以往的模型中，只能用一个具有固定语气、风格的“人”来和用户交互。但是在`GPT-4`，允许通过配置的方式，在被允许的范围内，定制这个风格。

官方有个例子，可以给模型定义使用苏格拉底的风格来答复问题。

## 局限性
`GPT-4`还是会存在瞎编乱造、偏见的情况。
预训练的数据集是在2021年9月份之前的，但是在后续的微调版本中，不排除会加入新的数据集。
当前可以支持8192个Token的规模。（平均来说，一个英文单词会被分为1.3个Token，一个汉字会被分为2个Token）

## 参考来源

[1] https://www.youtube.com/watch?v=K0SZ9mdygTw&list=RDCMUC8WCW6C3BWLKSZ5cMzD8Gyw&index=1   
[2] https://openai.com/research/gpt-4   
[3] https://wanzhanyong.blog.caixin.com/archives/265251